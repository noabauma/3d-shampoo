name;module;shape;partitioning_ranks;prec_matrices
module.4.input_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);0;
module.4.input_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);0;
module.4.attention.query_key_value;ColumnParallelLinear();(3072, 1024);0;
module.4.attention.query_key_value;ColumnParallelLinear();(3072,);0;
module.4.attention.dense;RowParallelLinear();(1024, 1024);0;
module.4.attention.dense;RowParallelLinear();(1024,);0;
module.4.post_attention_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);0;
module.4.post_attention_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);0;
module.4.mlp.dense_h_to_4h;ColumnParallelLinear();(4096, 1024);0;
module.4.mlp.dense_h_to_4h;ColumnParallelLinear();(4096,);0;
module.4.mlp.dense_4h_to_h;RowParallelLinear();(1024, 4096);0;
module.4.mlp.dense_4h_to_h;RowParallelLinear();(1024,);0;
module.5.input_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);1;[]
module.5.input_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);1;[]
module.5.attention.query_key_value;ColumnParallelLinear();(3072, 1024);1;[torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024]), torch.Size([384, 384]), torch.Size([1024, 1024])]
module.5.attention.query_key_value;ColumnParallelLinear();(3072,);1;[]
module.5.attention.dense;RowParallelLinear();(1024, 1024);1;[torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128]), torch.Size([1024, 1024]), torch.Size([128, 128])]
module.5.attention.dense;RowParallelLinear();(1024,);1;[]
module.5.post_attention_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);1;[]
module.5.post_attention_layernorm;FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True);(1024,);1;[]
module.5.mlp.dense_h_to_4h;ColumnParallelLinear();(4096, 1024);1;[torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024])]
module.5.mlp.dense_h_to_4h;ColumnParallelLinear();(4096,);1;[]
module.5.mlp.dense_4h_to_h;RowParallelLinear();(1024, 4096);1;[torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512]), torch.Size([1024, 1024]), torch.Size([512, 512])]
module.5.mlp.dense_4h_to_h;RowParallelLinear();(1024,);1;[]
